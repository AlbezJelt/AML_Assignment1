{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAXWLnLIJHi_"
      },
      "source": [
        "# **Advanced Machine Learning - Assignment 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmpYOHP4KYgT"
      },
      "source": [
        "Let's define the training dataset import function, fetching directly from the Github repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i19eu0hJR6n"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def merge_training_dataset(feature_set, label_set):\n",
        "    merged = pd.merge(feature_set, label_set, on='id')\n",
        "    return merged\n",
        "\n",
        "def import_training_dataset():\n",
        "  url_features = 'https://github.com/AlbezJelt/AML_Assignment1/raw/main/data/X_train.csv'\n",
        "  url_labels = 'https://github.com/AlbezJelt/AML_Assignment1/raw/main/data/y_train.csv'\n",
        "  feature_set = pd.read_csv(url_features).rename(columns={'Unnamed: 0':'id'})\n",
        "  label_set = pd.read_csv(url_labels).rename(columns={'Unnamed: 0':'id'})\n",
        "  train_set = merge_training_dataset(feature_set, label_set)\n",
        "  train_set.drop('id', axis=1, inplace=True)\n",
        "  return train_set\n",
        "\n",
        "train_set = import_training_dataset()\n",
        "test_set = train_set.sample(frac=0.2, random_state=42)\n",
        "train_set = train_set.drop(test_set.index)\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErTM_X4mKwU1"
      },
      "source": [
        "Now we can explore the pandas datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou1GqWETY4VW",
        "outputId": "08d7f760-c64c-457c-ebff-caaa81d58838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "train_stats = train_set.describe()\n",
        "train_stats.pop(\"latitude\")\n",
        "train_stats.pop(\"longitude\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>minimum_nights</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>7.166562</td>\n",
              "      <td>19.936023</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>999.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_reviews</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>23.310510</td>\n",
              "      <td>44.342583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>23.00</td>\n",
              "      <td>629.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_per_month</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>1.093855</td>\n",
              "      <td>1.618335</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.59</td>\n",
              "      <td>58.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>7.251743</td>\n",
              "      <td>33.307034</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>327.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>availability_365</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>112.831925</td>\n",
              "      <td>131.551035</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>45.00</td>\n",
              "      <td>226.00</td>\n",
              "      <td>365.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Private_room</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>0.455307</td>\n",
              "      <td>0.498008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Entire_home/apt</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>0.521194</td>\n",
              "      <td>0.499560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>27107.0</td>\n",
              "      <td>153.695724</td>\n",
              "      <td>253.309864</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.00</td>\n",
              "      <td>105.00</td>\n",
              "      <td>176.00</td>\n",
              "      <td>10000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  count        mean  ...     75%      max\n",
              "minimum_nights                  27107.0    7.166562  ...    5.00    999.0\n",
              "number_of_reviews               27107.0   23.310510  ...   23.00    629.0\n",
              "reviews_per_month               27107.0    1.093855  ...    1.59     58.5\n",
              "calculated_host_listings_count  27107.0    7.251743  ...    2.00    327.0\n",
              "availability_365                27107.0  112.831925  ...  226.00    365.0\n",
              "Private_room                    27107.0    0.455307  ...    1.00      1.0\n",
              "Entire_home/apt                 27107.0    0.521194  ...    1.00      1.0\n",
              "price                           27107.0  153.695724  ...  176.00  10000.0\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li7Sxz0qK7xz"
      },
      "source": [
        "sns.pairplot(train_set[[\"minimum_nights\", \"number_of_reviews\", \"reviews_per_month\", \"calculated_host_listings_count\", \"availability_365\"]], diag_kind=\"kde\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b8OBo7UlZnl"
      },
      "source": [
        "Now we begin with the model creation. First of all we sepair the labels (in this case the price column) from the train set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zepJ8crzl1kb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def prepare_data(train_set, test_set):\n",
        "    Y_train = train_set.copy().pop(\"price\").to_numpy(dtype=np.float32)\n",
        "    Y_test = test_set.copy().pop(\"price\").to_numpy(dtype=np.float32)\n",
        "    return train_set.copy().to_numpy(dtype=np.float32), Y_train, test_set.copy().to_numpy(dtype=np.float32), Y_test\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = prepare_data(train_set, test_set)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRsuk7_7mwTm"
      },
      "source": [
        "Then we proceed to normalize data. Remember to normalize the validation set too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V__EwUe7oA-T",
        "outputId": "c31548cf-ee8c-437d-dd1b-c9fa78bde96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocess_data(X : np.ndarray, scaler=None):\n",
        "    if not scaler:\n",
        "        scaler = RobustScaler()\n",
        "    if X.ndim == 1:\n",
        "        X = np.squeeze(scaler.fit_transform(X.reshape(-1, 1)))\n",
        "    else:\n",
        "        X = scaler.fit_transform(X)      \n",
        "    return X\n",
        "\n",
        "X_train = preprocess_data(X_train, StandardScaler())\n",
        "Y_train = preprocess_data(Y_train, StandardScaler())"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27107, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYE2LpgE62nr",
        "outputId": "5d7bacd8-8895-4ffd-9433-007d980dde0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "\n",
        "def build_model(train_dataset):\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1], )),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss=root_mean_squared_error,\n",
        "                optimizer=optimizer,\n",
        "                metrics=[root_mean_squared_error, 'mse'])\n",
        "  return model\n",
        "\n",
        "model = build_model(X_train)\n",
        "model.summary()\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,929\n",
            "Trainable params: 4,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0DmNNH8CQJq",
        "outputId": "8e4a4486-1b92-416f-cbb3-3e28d1c4366b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(X_train, Y_train):\n",
        "    model.fit(X_train[train], Y_train[train], epochs=25, verbose=False)\n",
        "    scores = model.evaluate(X_train[train], Y_train[train], verbose=False)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
        "    fold_no = fold_no + 1"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score for fold 1: loss of 0.01549906563013792; root_mean_squared_error of 0.015496984124183655\n",
            "Score for fold 2: loss of 0.005724536720663309; root_mean_squared_error of 0.005723513197153807\n",
            "Score for fold 3: loss of 0.009551148861646652; root_mean_squared_error of 0.009549764916300774\n",
            "Score for fold 4: loss of 0.011755700223147869; root_mean_squared_error of 0.011749790981411934\n",
            "Score for fold 5: loss of 0.005230107344686985; root_mean_squared_error of 0.005230754613876343\n",
            "Score for fold 6: loss of 0.005272132810205221; root_mean_squared_error of 0.005271930247545242\n",
            "Score for fold 7: loss of 0.00594754982739687; root_mean_squared_error of 0.005946459248661995\n",
            "Score for fold 8: loss of 0.006926438305526972; root_mean_squared_error of 0.006927221082150936\n",
            "Score for fold 9: loss of 0.005190389230847359; root_mean_squared_error of 0.005190315190702677\n",
            "Score for fold 10: loss of 0.011581392958760262; root_mean_squared_error of 0.01158023253083229\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}